{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the game\n",
        "payoff_matrix = np.array([[3, 0], [4, 1]])\n",
        "actions = ['C', 'D']\n",
        "num_players = 2\n",
        "num_actions = 2\n",
        "\n",
        "# Define the prior belief over the types\n",
        "prior = np.ones((num_players, 2)) / 2\n",
        "\n",
        "# Define the information structure\n",
        "def information_structure(player, other_player):\n",
        "    if player == 0:\n",
        "        if other_player == 1:\n",
        "            return [0.5, 0.5]  # Type A\n",
        "        else:\n",
        "            return [0.1, 0.9]  # Type B\n",
        "    else:\n",
        "        if other_player == 0:\n",
        "            return [0.5, 0.5]  # Type A\n",
        "        else:\n",
        "            return [0.1, 0.9]  # Type B\n",
        "\n",
        "# Run Bayesian inference\n",
        "num_samples = 10000\n",
        "player_types = np.zeros((num_players, num_samples), dtype=int)\n",
        "player_actions = np.zeros((num_players, num_players, num_samples), dtype=int)\n",
        "player_payoffs = np.zeros((num_players, num_samples))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    # Sample player types from the prior\n",
        "    player_types[:, i] = np.random.choice(2, 2, p=prior[:, 0])\n",
        "\n",
        "    # Choose player actions based on their types and the information structure\n",
        "    for j in range(num_players):\n",
        "        for k in range(num_players):\n",
        "            if j != k:\n",
        "                action_probs = information_structure(k, j)\n",
        "                player_actions[j, k, i] = np.random.choice(2, p=action_probs)\n",
        "\n",
        "    # Calculate player payoffs based on their actions and the payoff matrix\n",
        "    for j in range(num_players):\n",
        "        payoff = 0\n",
        "        for k in range(num_players):\n",
        "            if j != k:\n",
        "                action = player_actions[k, j, i]\n",
        "                payoff += payoff_matrix[player_types[j, i], player_types[k, i]] [action]\n",
        "        player_payoffs[j, i] = payoff\n",
        "\n",
        "# Calculate the posterior distributions over player types\n",
        "posterior = np.zeros((num_players, 2))\n",
        "for i in range(num_players):\n",
        "    for j in range(2):\n",
        "        posterior[i, j] = np.mean(player_types[i] == j)\n",
        "\n",
        "# Find the Nash equilibrium\n",
        "nash_eq = np.zeros(num_players, dtype=int)\n",
        "for i in range(num_players):\n",
        "    if posterior[i, 0] > posterior[i, 1]:\n",
        "        nash_eq[i] = 0\n",
        "    elif posterior[i, 0] < posterior[i, 1]:\n",
        "        nash_eq[i] = 1\n",
        "    else:\n",
        "        nash_eq[i] = np.random.choice(2)\n",
        "\n",
        "# Print the results\n",
        "print('Player 1 type A probability: {:.2f}'.format(posterior[0, 0]))\n",
        "print('Player 2 type A probability: {:.2f}'.format(posterior[1, 0]))\n",
        "print('Nash equilibrium: {}'.format([actions[i] for i in nash_eq]))\n"
      ],
      "metadata": {
        "id": "o-nfaAEPylgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "40760d27-d661-457c-d25f-4137b67610cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-684000b159a7>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mpayoff\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpayoff_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mplayer_payoffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qqItYynw8CaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}